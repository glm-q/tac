{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La détection de langue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons ici la librairie langid:\n",
    "    \n",
    "https://pypi.org/project/langid/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import langid\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forcer l'algorithme à ne détecter que du Français et du Néerlandais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "langid.set_languages(['fr', 'nl'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lister tous les documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7936 TXT files found\n"
     ]
    }
   ],
   "source": [
    "root = \"../data/txt/\"\n",
    "txts = os.listdir(root)\n",
    "print(f\"{len(txts)} TXT files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détecter la langue pour tous les documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons lire chaque fichier, détecter la langue, et incrémenter `lang_dict` lorsqu'une langue est détectée.\n",
    "\n",
    "**Important** : pour détecter les langues sur tous les documents, mettez `limit = None` ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 500\n",
    "# limit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dict = defaultdict(int)\n",
    "txts = txts[:limit] if limit else texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 document(s) processed...\n",
      "KB_JB838_1887-12-23_01-00002.txt contains only 1 characters, treating as unknown\n",
      "50 document(s) processed...\n",
      "100 document(s) processed...\n",
      "150 document(s) processed...\n",
      "200 document(s) processed...\n",
      "250 document(s) processed...\n",
      "300 document(s) processed...\n",
      "350 document(s) processed...\n",
      "400 document(s) processed...\n",
      "450 document(s) processed...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for i, txt in enumerate(sorted(txts)):\n",
    "    if txt.endswith(\"txt\"):\n",
    "        if i % 50 == 0:\n",
    "            print(f'{i} document(s) processed...')\n",
    "        text = open(os.path.join(root, txt), \"r\", encoding=\"utf-8\").read()\n",
    "        text_length = len(text)\n",
    "        if text_length > 20:\n",
    "            lang, conf = langid.classify(text)\n",
    "            lang_dict[lang] += 1\n",
    "        else:\n",
    "            print(f\"{txt} contains only {text_length} characters, treating as unknown\")\n",
    "            lang_dict['n/a'] += 1\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afficher le nombre de documents par langue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French\t499\n",
      "None\t1\n"
     ]
    }
   ],
   "source": [
    "for lang_code, nb_docs in lang_dict.items():\n",
    "    language = pycountry.languages.get(alpha_2=lang_code)\n",
    "    try:\n",
    "        lang_name = language.name\n",
    "    except AttributeError:\n",
    "        lang_name = language\n",
    "    print(f\"{lang_name}\\t{nb_docs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('tac_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c41795ef67e28f443d51e3530ac426b505c5d8c966af08c2f17a523686b1e2cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
